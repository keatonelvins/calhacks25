model = "Qwen/Qwen3-4B-Instruct-2507"

[env]
id = "primeintellect/wiki-search"

[inference]
gpus = 6

[inference.args]
enforce_eager = true

[trainer]
gpus = 2

[trainer.args]
run_name = "wiki-search"
micro_batch_size = 8
rollouts_per_example = 16
batch_size = 512
max_steps = 500
max_seq_len = 4096
output_dir = "/artifacts/wiki-search"