model = "Qwen/Qwen3-4B-Instruct-2507"

[env]
id = "will/wordle"

[inference]
gpus = 6
tensor_parallel_size = 6

[inference.args]
enforce_eager = true

[trainer]
gpus = 2

[trainer.args]
run_name = "wordle"
output_dir = "/artifacts/wordle"
lora_target_modules = "all-linear"
micro_batch_size = 8
rollouts_per_example = 8
batch_size = 512
max_steps = 500
max_seq_len = 4096
use_liger_kernel = true